{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting diabetes\n",
    "\n",
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# do plotting inline instead of separate window\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/pima-data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preg</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diab_pred</th>\n",
       "      <th>age</th>\n",
       "      <th>skin</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1.3790</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>1.1426</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3790</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1.2608</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1.7730</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  diab_pred  \\\n",
       "0         6           148            72         35        0  33.6      0.627   \n",
       "1         1            85            66         29        0  26.6      0.351   \n",
       "2         8           183            64          0        0  23.3      0.672   \n",
       "3         1            89            66         23       94  28.1      0.167   \n",
       "4         0           137            40         35      168  43.1      2.288   \n",
       "5         5           116            74          0        0  25.6      0.201   \n",
       "6         3            78            50         32       88  31.0      0.248   \n",
       "7        10           115             0          0        0  35.3      0.134   \n",
       "8         2           197            70         45      543  30.5      0.158   \n",
       "9         8           125            96          0        0   0.0      0.232   \n",
       "\n",
       "   age    skin diabetes  \n",
       "0   50  1.3790     True  \n",
       "1   31  1.1426    False  \n",
       "2   32  0.0000     True  \n",
       "3   21  0.9062    False  \n",
       "4   33  1.3790     True  \n",
       "5   30  0.0000    False  \n",
       "6   26  1.2608     True  \n",
       "7   29  0.0000    False  \n",
       "8   53  1.7730     True  \n",
       "9   54  0.0000     True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape  #number of rows and of cols\n",
    "df.head(10) #show first ten rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preg</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diab_pred</th>\n",
       "      <th>age</th>\n",
       "      <th>skin</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>1.8912</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0638</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>1.2214</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  \\\n",
       "763        10           101            76         48      180  32.9   \n",
       "764         2           122            70         27        0  36.8   \n",
       "765         5           121            72         23      112  26.2   \n",
       "766         1           126            60          0        0  30.1   \n",
       "767         1            93            70         31        0  30.4   \n",
       "\n",
       "     diab_pred  age    skin diabetes  \n",
       "763      0.171   63  1.8912    False  \n",
       "764      0.340   27  1.0638    False  \n",
       "765      0.245   30  0.9062    False  \n",
       "766      0.349   47  0.0000     True  \n",
       "767      0.315   23  1.2214    False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#or also the last records\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use matplot to detect correlated columns by cross-plotting\n",
    "def plot_corr(df, size=10):\n",
    "    \"\"\"\n",
    "    Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n",
    "\n",
    "    Input:\n",
    "        df: pandas DataFrame\n",
    "        size: vertical and horizontal size of the plot\n",
    "\n",
    "    Displays:\n",
    "        matrix of correlation between columns.  Blue-cyan-yellow-red-darkred => less to more correlated\n",
    "                                                0 ------------------>  1\n",
    "                                                Expect a darkred line running from top left to bottom right\n",
    "    \"\"\"\n",
    "\n",
    "    corr = df.corr()    # data frame correlation function\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    ax.matshow(corr)   # color code the rectangles by correlation value\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns)  # draw x tick marks\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)  # draw y tick marks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnsAAAJDCAYAAABzHdJXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9fbafd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_corr(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preg</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diab_pred</th>\n",
       "      <th>age</th>\n",
       "      <th>skin</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_preg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.221898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose_conc</th>\n",
       "      <td>0.129459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.466581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diastolic_bp</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.065068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thickness</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insulin</th>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.292695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diab_pred</th>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.173844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>0.238356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skin</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.466581</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.130548</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              num_preg  glucose_conc  diastolic_bp  thickness   insulin  \\\n",
       "num_preg      1.000000      0.129459      0.141282  -0.081672 -0.073535   \n",
       "glucose_conc  0.129459      1.000000      0.152590   0.057328  0.331357   \n",
       "diastolic_bp  0.141282      0.152590      1.000000   0.207371  0.088933   \n",
       "thickness    -0.081672      0.057328      0.207371   1.000000  0.436783   \n",
       "insulin      -0.073535      0.331357      0.088933   0.436783  1.000000   \n",
       "bmi           0.017683      0.221071      0.281805   0.392573  0.197859   \n",
       "diab_pred    -0.033523      0.137337      0.041265   0.183928  0.185071   \n",
       "age           0.544341      0.263514      0.239528  -0.113970 -0.042163   \n",
       "skin         -0.081672      0.057328      0.207371   1.000000  0.436783   \n",
       "diabetes      0.221898      0.466581      0.065068   0.074752  0.130548   \n",
       "\n",
       "                   bmi  diab_pred       age      skin  diabetes  \n",
       "num_preg      0.017683  -0.033523  0.544341 -0.081672  0.221898  \n",
       "glucose_conc  0.221071   0.137337  0.263514  0.057328  0.466581  \n",
       "diastolic_bp  0.281805   0.041265  0.239528  0.207371  0.065068  \n",
       "thickness     0.392573   0.183928 -0.113970  1.000000  0.074752  \n",
       "insulin       0.197859   0.185071 -0.042163  0.436783  0.130548  \n",
       "bmi           1.000000   0.140647  0.036242  0.392573  0.292695  \n",
       "diab_pred     0.140647   1.000000  0.033561  0.183928  0.173844  \n",
       "age           0.036242   0.033561  1.000000 -0.113970  0.238356  \n",
       "skin          0.392573   0.183928 -0.113970  1.000000  0.074752  \n",
       "diabetes      0.292695   0.173844  0.238356  0.074752  1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we find that the skin and thickness columns are correlated, \n",
    "# this is especially noticeable when the feature 's value is 0\n",
    "# so we delete skin column\n",
    "del df['skin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preg</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diab_pred</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  diab_pred  \\\n",
       "0         6           148            72         35        0  33.6      0.627   \n",
       "1         1            85            66         29        0  26.6      0.351   \n",
       "2         8           183            64          0        0  23.3      0.672   \n",
       "\n",
       "   age diabetes  \n",
       "0   50     True  \n",
       "1   31    False  \n",
       "2   32     True  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and verify by checking the head again\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnsAAAJDCAYAAABzHdJXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVLDDHuSJEkNM+xJkiQ1zLAnSZLUsP8f8Vqf9PLlMbYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa2517b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot again to see if corrleation has been done away with\n",
    "plot_corr(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data types \n",
    "\n",
    "Now we can move on to molding the data, which means:\n",
    "\n",
    "* adjusting data types\n",
    "* creating new columns if necessary\n",
    "\n",
    "For many algorithms all values have to be numerical, so often we need to change booleans to 0 and 1, as below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bool_map = {True: 1, False: 0}\n",
    "# map the col again\n",
    "df['diabetes'] = df['diabetes'].map(bool_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preg</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diab_pred</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  diab_pred  \\\n",
       "0         6           148            72         35        0  33.6      0.627   \n",
       "1         1            85            66         29        0  26.6      0.351   \n",
       "2         8           183            64          0        0  23.3      0.672   \n",
       "\n",
       "   age  diabetes  \n",
       "0   50         1  \n",
       "1   31         0  \n",
       "2   32         1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check again if data has been converted \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data distribution\n",
    "\n",
    "Another important thing is to ensure that the data is dsitributed well enough to allow us to use the data to train the algorithm. Bear in mind that **predicting rare events with accuracy is difficult**. (black swans etc. this is well documented and very interestingly described in the work of Nassim Taleb). The change of having rare events in our training data is low, or they would not be rare events at all.\n",
    "\n",
    "## Check true/false ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True cases:  268 (34.90%)\n",
      "Number of False cases: 500 (65.10%)\n"
     ]
    }
   ],
   "source": [
    "num_T = len(df.loc[df['diabetes'] == True])\n",
    "num_F = len(df.loc[df['diabetes'] == False])\n",
    "print(\"Number of True cases:  {0} ({1:2.2f}%)\".format(num_T,(num_T/ (num_T + num_F))*100))\n",
    "print(\"Number of False cases: {0} ({1:2.2f}%)\".format(num_F,(num_F/ (num_T + num_F))*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with 35% we can reasonably expect to train the model well. There are other special advanced techniques for trying to predict things that do not happen that very often. With these ratios we can use standard prediction techniques.\n",
    "\n",
    "Now that we have performed several manipulations, it is important to state that we always need to **track how the data was manipulated**. A lot of the data manipulation in ML is actually trial and error. When we manipulate the data, it is very easy to **change the meaning of the data**, especially unintentionally. These Jupyter notebooks are useful for tracking everything we do to the data. Python interpreter interaction is stored via code cells. Documentation in markdown, such as this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the algorithm\n",
    "\n",
    "Use your problem domain knowledge to select the initial algo. This is where the initial problem statement we did will help us filter the search for the algo, if it was done well enough. In ML it will often be the case that the initial algo is not the right one and we will have to go through the workflow several times, therefore training and evaluation multiple algos.\n",
    "\n",
    "## Role of the Algorithm\n",
    "\n",
    "Naturally, the algo is what drives the entire process, but there are two phases, training and real use case. We use the algo both to create and use a trained model. When in training, when the training function (a.k.a. \"fit\") is called, the algo executes its logic and processes the training set. The resulting analysis is evaluated against a mathematical model and logic associated with the algo. Then the algo uses this analysis to produce a model that best fits the data in the training dataset. Now the fit parameters are stored and the model is now said to be trained. \n",
    "\n",
    "Now comes real use and the model is called via the prediction function (a.k.a. \"predict\") and real data is passed to the model, which uses its code and parameter values to produce a result.\n",
    "\n",
    "## Algorithm selection\n",
    "\n",
    "There are plenty of available algorithms. Scikit-learn for example contains more than 50 and more are being created. \n",
    "\n",
    "There are several factors to take into account initially to select an algo\n",
    "\n",
    "* Learning Type (supervised or not)\n",
    "\n",
    "* Result we want (results are divided between *regression* and *classification*) - *Regression* means continuous values, such as prices, whereas *classification* implies discrete values. Many algos support both kinds of results.\n",
    "\n",
    "* Complexity, eliminate \"ensemble\" algos, which are container algos with multiple child algos under the surface. These are more often used to tune and boost performance; also they tend to be difficult to diagnose and debug.\n",
    "\n",
    "* Basic vs enhanced algorithm; enhanced algos are variations of basic algos, often for performance imprvements, additional functionality, and thus they tend to be more complex.\n",
    "\n",
    "\n",
    "So, for this example we are basically down to three classic options\n",
    "\n",
    "* Naive Bayes, based on Bayes' theorem of likelihood and probability. Every feature has the same weight. Requires less data and allows for fast conversions. Looks at nearby values to estimate probability. It is simple to understand and train, and fast too, as other algorithms can take 100x times to train. This algo is stable to changes to the data.\n",
    "* Logistic Regression. In spite of the name implying continuous values (regression), this is a binary result algo. It measures the relationship of each feture and weights them on their impact on the result. The resultant value is mapped against a curve\n",
    "* Decision Tree\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We want to make sure to do the training with the minimun features possible, this makes the training go faster. We will use scikit-learn.\n",
    "\n",
    "We will also split the data 70%-30% and never use the test data for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the data\n",
    "\n",
    "# this is deprecated\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "\n",
    "feature_col_names = ['num_preg', 'glucose_conc', 'diastolic_bp', 'thickness', 'insulin', 'bmi', 'diab_pred', 'age']\n",
    "predicted_col_names = ['diabetes']\n",
    "\n",
    "x = df[feature_col_names].values\n",
    "y = df[predicted_col_names].values\n",
    "split_test_size =0.3\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x,y, test_size = split_test_size, random_state = 42)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cehck that we have the desired 70% 30% train vs test split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.92% in training set\n",
      "30.08% in test set\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:0.2f}% in training set\".format((len(X_train) / len(df.index))*100))\n",
    "print(\"{0:0.2f}% in test set\".format((len(X_test) / len(df.index))*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we also need to ensure there is a good split of true and false cases, not a skewed one\n",
    "(code missing yet)\n",
    "\n",
    "## Post-split data preparation\n",
    "\n",
    "Perform data transformation post-split separately on the test and train datasets to ensure they remain separate.\n",
    "\n",
    "#### find hidden missing values\n",
    "\n",
    "Sometimes a 0 is actually a missing value. Are 0 values possible? How many rows do have these 0s? Which ones are really an issue? This is when a domain expert can come in handy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in the data frame {0} 768\n",
      "Rows missing glucose_conc: 5\n",
      "Rows missing diastolic_bp: 35\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows in the data frame {0}\", format(len(df)))\n",
    "print(\"Rows missing glucose_conc: {0}\".format(len(df.loc[df['glucose_conc'] == 0])))\n",
    "print(\"Rows missing diastolic_bp: {0}\".format(len(df.loc[df['diastolic_bp'] == 0])))\n",
    "# and so on for the rest of the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data is a common problem. We can ignore, drop the rows, replace the values (impute). Imputing is a common option, either by replacing with mean, median etc or replacing with a value derived expert domain knowledge \n",
    "\n",
    "#### impute with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "fill_0 = Imputer(missing_values = 0, strategy=\"mean\", axis=0)\n",
    "\n",
    "X_train = fill_0.fit_transform(X_train)\n",
    "X_test = fill_0.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the initial algo, Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "nb_model.fit(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict values using the training data\n",
    "nb_predict_train = nb_model.predict(X_train)\n",
    "# for this we can use the metrics library\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy {0:.4f}\".format(metrics.accuracy_score(Y_train, nb_predict_train)))\n",
    "print()\n",
    "\n",
    "#gives us over 70% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict values using the training data\n",
    "nb_predict_test = nb_model.predict(X_test)\n",
    "# for this we can use the metrics library\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy {0:.4f}\".format(metrics.accuracy_score(Y_test, nb_predict_test)))\n",
    "print()\n",
    "\n",
    "#gives us over 70% accuracy as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "\n",
    "how did we really get to these numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 52  28]\n",
      " [ 33 118]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.65      0.63        80\n",
      "          0       0.81      0.78      0.79       151\n",
      "\n",
      "avg / total       0.74      0.74      0.74       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Confusion matrix\")\n",
    "# labels for 1 = True and 0 = False \n",
    "print(\"{0}\".format(metrics.confusion_matrix(Y_test, nb_predict_test, labels=[1,0])))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Classification report\")\n",
    "print(metrics.classification_report(Y_test, nb_predict_test, labels=[1,0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the results and the matrix\n",
    "\n",
    "the results are \n",
    "\n",
    "                TP FP\n",
    "                FN TN\n",
    "\n",
    "where TP = true positive (actual diabetes and predicted to be diabetes), FN is false negative (actual diabetes, but predicted to be not diabetes), FP = false positive (actual not diabetes but predicted to be diabetes), TN = true negative (actual not diabetes and predicted to be not diabetes) \n",
    "\n",
    "in a perfect world we would get 0 instead of the 28 and the 33\n",
    "\n",
    "#### recall\n",
    "\n",
    "recall is the true positive rate, which basically tells us how well the model predicts diabetes. Recall is calculated as follows: TP / ( TP + FN ). In this case we have .65, but we should aspire to get > 70%\n",
    "\n",
    "#### precision\n",
    "\n",
    "The positive predictor value, that is, how often a patient gets diabetes when the model said they would: confirmation. It is TP / ( TP / + FP ). We would like to increase that number too as that would mean fewer false positives.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving performance\n",
    "\n",
    "There are several strategies\n",
    "\n",
    "* adjust current algo (via hyperparameters), but our naive bayes does not have such paraemters\n",
    "* get more data or improve it\n",
    "* improve the training\n",
    "* switch to another algo\n",
    "\n",
    "\n",
    "Let's try *Random Forest*\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "RF is an ensemble algo, based on decision trees. It creates mutiple such trees and fits multiple trees with subsets of the data. Then the results of the trees are averaged in order to improve performance and control the risk of overfitting, as that is a tendency with tree algorithms.\n",
    "\n",
    "Let's train the RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(random_state = 42)\n",
    "rf_model.fit(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9870\n"
     ]
    }
   ],
   "source": [
    "# now check accuracy\n",
    "\n",
    "rf_predict_train = rf_model.predict(X_train)\n",
    "print(\"Accuracy {0:.4f}\".format(metrics.accuracy_score(Y_train, rf_predict_train )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the test data we got very good accuracy. Let's see the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7100\n"
     ]
    }
   ],
   "source": [
    "rf_predict_test = rf_model.predict(X_test)\n",
    "print(\"Accuracy {0:.4f}\".format(metrics.accuracy_score(Y_test, rf_predict_test )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 43  37]\n",
      " [ 30 121]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.54      0.56        80\n",
      "          0       0.77      0.80      0.78       151\n",
      "\n",
      "avg / total       0.70      0.71      0.71       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Confusion matrix\")\n",
    "# labels for 1 = True and 0 = False \n",
    "print(\"{0}\".format(metrics.confusion_matrix(Y_test, rf_predict_test, labels=[1,0])))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Classification report\")\n",
    "print(metrics.classification_report(Y_test, rf_predict_test, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the results are not that good on the test data. Recall is too low, and so is precision. This seems a classic example of ***overfitting***. This results from a decision boundary that is too complex, that is, a boundary that fits too well the data distribution in the training set, but that would not work nearly as well on the test set, or any other real-world data with a different distribution.\n",
    "\n",
    "### How to fix overfitting\n",
    "\n",
    "One option is the use of **Hyperparameters**, that define how the algo operates and learns. There is one specific param that affects overfitting, usually called *regularization*, which specifies to what extent the algo should focus on every corner case of the training data ( value dampening ).\n",
    "\n",
    "Another mechanism to reduce overfitting is **Cross Validation**. \n",
    "\n",
    "Both options can be used at the same time.\n",
    "\n",
    "Accuracy with both training and testing data is often called the ***bias-variance trade-off***, something that must be considered in almost all supervised ML algos. We need to sacrifice some perfection in traning in order to get better overall performance with test and real world datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try something simpler now, Logistic Regression\n",
    "\n",
    "We can not only switch to more complex algorithms, but also to simpler ones. Logistic Regression is simple in form but performs well in many classification scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7446\n",
      "Confusion matrix\n",
      "[[ 44  36]\n",
      " [ 23 128]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.55      0.60        80\n",
      "          0       0.78      0.85      0.81       151\n",
      "\n",
      "avg / total       0.74      0.74      0.74       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(C=0.7, random_state=42)# 0.7 as regularization param here is only a starting guess\n",
    "lr_model.fit(X_train, Y_train.ravel())\n",
    "\n",
    "\n",
    "lr_predict_test = lr_model.predict(X_test)\n",
    "print(\"Accuracy {0:.4f}\".format(metrics.accuracy_score(Y_test, lr_predict_test )))\n",
    "\n",
    "\n",
    "print (\"Confusion matrix\")\n",
    "# labels for 1 = True and 0 = False \n",
    "print(metrics.confusion_matrix(Y_test, lr_predict_test, labels=[1,0]))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Classification report\")\n",
    "print(metrics.classification_report(Y_test, lr_predict_test, labels=[1,0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Promising but not good enough. Let's set a regularization parameter in a loop and try to see which value returns the best recall value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st max value of 0.613 found at C = 1.400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xa3c5ac8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYWZmJXHCMDOzkvx/qvJLIT1uau0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa1a1908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C_start= 0.1\n",
    "C_end = 5\n",
    "C_inc = 0.1\n",
    "\n",
    "C_values, recall_scores = [], []\n",
    "\n",
    "C_val = C_start\n",
    "best_recall_score = 0\n",
    "\n",
    "while(C_val < C_end):\n",
    "    C_values.append(C_val)\n",
    "    lr_model_loop = LogisticRegression(C=C_val, random_state=42)\n",
    "    lr_model_loop.fit(X_train, Y_train.ravel())\n",
    "    lr_predict_loop_test = lr_model_loop.predict(X_test)\n",
    "    recall_score = metrics.recall_score(Y_test, lr_predict_loop_test )\n",
    "    recall_scores.append(recall_score)\n",
    "    if(recall_score > best_recall_score):\n",
    "        best_recall_score = recall_score\n",
    "        best_lr_predict_test = lr_predict_loop_test\n",
    "        \n",
    "    C_val = C_val + C_inc\n",
    "\n",
    "\n",
    "best_score_C_val = C_values[recall_scores.index(best_recall_score)]\n",
    "\n",
    "print(\"1st max value of {0:.3f} found at C = {1:.3f}\".format(best_recall_score, best_score_C_val))\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot(C_values, recall_scores, \"-\")\n",
    "plt.xlabel(\"C value\")\n",
    "plt.ylabel(\"recall_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not getting a recall value over .7 !!\n",
    "\n",
    "Our data had more non-diabetes than diabetes results. This could cause an imbalance issue. Unfortunately *unbalanced classes* are very common in datasets. So we need to understand how to fix them.\n",
    "\n",
    "### Fix unbalanced classes\n",
    "\n",
    "THese occur when we have more of one class result than of the other, such as diabetes vs non-diabetes here, where we had 35% and 65% respectively. Seems like a big imbalance. This can decrease the performance of an algorithm. However, the algo can include another parameter to compensate for this class imbalance. Manipulating this parameter changes the decision boundary. We need to enable this in our algo here.\n",
    "\n",
    "#### Logistic regression with class_weight='balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st max value of 0.738 found at C = 0.300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x98f4160>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa42d9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C_start= 0.1\n",
    "C_end = 5\n",
    "C_inc = 0.1\n",
    "\n",
    "C_values, recall_scores = [], []\n",
    "\n",
    "C_val = C_start\n",
    "best_recall_score = 0\n",
    "\n",
    "while(C_val < C_end):\n",
    "    C_values.append(C_val)\n",
    "    lr_model_loop = LogisticRegression(C=C_val, class_weight=\"balanced\", random_state=42)\n",
    "    lr_model_loop.fit(X_train, Y_train.ravel())\n",
    "    lr_predict_loop_test = lr_model_loop.predict(X_test)\n",
    "    recall_score = metrics.recall_score(Y_test, lr_predict_loop_test )\n",
    "    recall_scores.append(recall_score)\n",
    "    if(recall_score > best_recall_score):\n",
    "        best_recall_score = recall_score\n",
    "        best_lr_predict_test = lr_predict_loop_test\n",
    "        \n",
    "    C_val = C_val + C_inc\n",
    "\n",
    "\n",
    "best_score_C_val = C_values[recall_scores.index(best_recall_score)]\n",
    "\n",
    "print(\"1st max value of {0:.3f} found at C = {1:.3f}\".format(best_recall_score, best_score_C_val))\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot(C_values, recall_scores, \"-\")\n",
    "plt.xlabel(\"C value\")\n",
    "plt.ylabel(\"recall_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7143\n",
      "Confusion matrix\n",
      "[[ 59  21]\n",
      " [ 45 106]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.74      0.64        80\n",
      "          0       0.83      0.70      0.76       151\n",
      "\n",
      "avg / total       0.74      0.71      0.72       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now we found a better value and we can re-run the algo with different values\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(C=best_score_C_val,class_weight=\"balanced\", random_state=42)# 0.7 as regularization param here is only a starting guess\n",
    "lr_model.fit(X_train, Y_train.ravel())\n",
    "\n",
    "\n",
    "lr_predict_test = lr_model.predict(X_test)\n",
    "print(\"Accuracy {0:.4f}\".format(metrics.accuracy_score(Y_test, lr_predict_test )))\n",
    "\n",
    "\n",
    "print (\"Confusion matrix\")\n",
    "# labels for 1 = True and 0 = False \n",
    "print(metrics.confusion_matrix(Y_test, lr_predict_test, labels=[1,0]))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Classification report\")\n",
    "print(metrics.classification_report(Y_test, lr_predict_test, labels=[1,0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we achieved the > 70% accuracy goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "We are familiar with the training vs test divide. But we had to tweak our algo on the training data as well, so it seems it would be better if we could have an additional set of data for validation. That is train and tweak the algo and its params on the training data, validate on the validation and finally run against the test. We could further split the data in 50%, 25% and 25% but that could be an issue if you do not have a lot of data to start with, and does this really mitigate overfitting? how could we be sure we would split the data in the right way?\n",
    "\n",
    "With ***K-Fold Cross validation***  we do not use the testing data, but we split the training data into several pieces (folds) each of the same size. One of them is chosen to be the validation set, and the rest are for training. And we repeat the process for all of the folds, changing the validation fold every time, so if we split in 8 folds initially, we would run this proces 8 times.\n",
    "\n",
    "For each fold we determine the best hyperparameter value and then we set the model's hyperparameter value to average best. We can use a package for this...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=3, class_weight='balanced', cv=10, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=-1, penalty='l2', random_state=42,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr_cv_model = LogisticRegressionCV(n_jobs=-1, random_state=42, Cs=3, cv=10, refit=True,class_weight=\"balanced\")\n",
    "lr_cv_model.fit(X_train, Y_train.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6926\n",
      "Confusion matrix\n",
      "[[ 52  28]\n",
      " [ 43 108]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.65      0.59        80\n",
      "          0       0.79      0.72      0.75       151\n",
      "\n",
      "avg / total       0.71      0.69      0.70       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_cv_predict_test = lr_cv_model.predict(X_test)\n",
    "print(\"Accuracy {0:.4f}\".format(metrics.accuracy_score(Y_test, lr_cv_predict_test )))\n",
    "\n",
    "\n",
    "print (\"Confusion matrix\")\n",
    "# labels for 1 = True and 0 = False \n",
    "print(metrics.confusion_matrix(Y_test, lr_cv_predict_test, labels=[1,0]))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Classification report\")\n",
    "print(metrics.classification_report(Y_test, lr_cv_predict_test, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen the algorithms have a lot parameters, so often it is a metter of trying a lot of variations, or having a lot  of experience!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
